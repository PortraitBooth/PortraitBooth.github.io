<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved Personalization</title>
  <link rel="icon" type="image/x-icon" href="static/images/myicon.ico?v=2">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  


  <section class="hero with-background">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <span class="custom-title">PortraitBooth</span>
              : A Versatile Portrait Model for Fast Identity-preserved Personalization
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Xu Peng</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Junwei Zhu</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Boyuan Jiang</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Ying Tai</a><sup>3</sup>,</span>
                      <span class="author-block">
                        <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Donghao Luo</a><sup>2</sup>,</span>
                        <span class="author-block">
                          <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Jiangning Zhang</a><sup>2</sup>,</span>
                          <span class="author-block">
                            <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Wei Lin</a><sup>1</sup>,</span>
                            <span class="author-block">
                              <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Taisong Jin</a><sup>1</sup>,</span>
                              <span class="author-block">
                                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Chengjie Wang</a><sup>2</sup>,</span>
                                <span class="author-block">
                                                                            
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Rongrong Ji</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Xiamen University,<sup>2</sup>Tencent,<sup>3</sup>Nanjing University</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
            </div>
          </div>
          <div style="background-color:#ffbf00; padding: 10px;text-align: left;margin-bottom: -20px">
            <p><strong>TL;DR:</strong> PortraitBooth allows for personalized generation of individual portraits from a <span style="color:green;">single image</span> while <span style="color:blue;">preserving identity</span>. The personalized generation includes expressions, actions, styles, age, skin tone, animation, and supports multi-subejct generation. <span style="color:red;">Importantly, our model achieves a low training cost by eliminating the need for substantial hardware resources during training or fine-tuning with multiple images during testing.</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero2">
  <img src="static/images/截屏2023-12-08 19.33.24.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in personalized image generation using diffusion models have been noteworthy. However, existing methods suffer from inefficiencies due to the requirement for subject-specific fine-tuning. This computationally intensive process hinders efficient deployment, limiting practical usability. Moreover, these methods often grapple with identity distortion and limited expression diversity. In light of these challenges, we propose PortraitBooth, an innovative approach designed for high efficiency, robust identity preservation, and expression-editable text-to-image generation, without the need for fine-tuning. PortraitBooth leverages subject embeddings from a face recognition model for personalized image generation without fine-tuning. It eliminates computational overhead and mitigates identity distortion. The introduced dynamic identity preservation strategy further ensures close resemblance to the original image identity. Moreover, PortraitBooth incorporates emotion-aware cross-attention control for diverse facial expressions in generated images, supporting text-driven expression editing. Its scalability enables efficient and high-quality image creation, including multi-subject generation. Extensive results demonstrate superior performance over other state-of-the-art methods in both single and multiple image generation scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->
<section class="divider1"></section>

<h2 class="title is-3">Method</h2>

<section class="hero1">
  <img src="static/images/截屏2023-12-10 15.31.36.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>

<div style="display: flex; justify-content: center;">
  <h2 class="subtitle" style="text-align:left; width:50%;">
    <span style="color:black;">Overview framework of PortraitBooth</span>. In the current field of portrait generation, most methods utilize a CLIP Image Encoder to extract the identity embedding from reference images. However, this approach only captures the superficial appearance without grasping the essence, and it fails to allow for expression editing. This has inspired us to develop a more advanced portrait generation method that not only maintains a higher level of identity preservation but also enables expression editing.
  </h2>
</div>
<section class="divider1"></section>

<section class="divider"></section>

<h2 class="title is-3">Expression Editing</h2>

<section class="hero1">
  <img src="static/images/s_m_p7.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>

<section class="hero1">
  <img src="static/images/s_m_p8.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>

<div style="display: flex; justify-content: center;">
  <h2 class="subtitle" style="text-align:left; width:50%;">
    Our model supports <span style="color:black;">diverse</span> facial expression and attribute editing while maintaining <span style="color:black;">high identity preservation </span>.
  </h2>
</div>
<section class="divider1"></section>
<section class="divider"></section>

<h2 class="title is-3">Comparisons</h2>
<section class="hero1">
  <img src="static/images/截屏2023-12-11 15.17.06.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>
<div style="display: flex; justify-content: center;">
  <h2 class="subtitle" style="text-align:left; width:50%;">
    Comparison with state-of-the-art methods in identity-preserving personalized portrait generation.
  </h2>
</div>
<section class="divider1"></section>
<section class="divider"></section>


<h2 class="title is-3">More results</h2>

<section class="hero1">
  <img src="static/images/截屏2023-12-09 19.05.44.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>


<section class="hero1">
  <img src="static/images/截屏2023-12-09 21.17.42.png" alt="Your Image Description" style="width: 50%; height: auto;">
  <!-- 你的内容 -->
</section>

<div style="display: flex; justify-content: center;">
  <h2 class="subtitle" style="text-align:left; width:50%;">
    <span style="color:black;">Our method is easily extendable</span>. It can be combined with multi-subject generation methods to achieve personalized portrait generation for multiple subjects.
  </h2>
</div>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container1">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/s_m_p3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Experimental results on the test set.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/截屏2023-12-08 14.41.22.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Experimental results on the test set.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/s_m_p5.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Experimental results on the test set.
        </h2>
     </div>

     <div class="item">
      <!-- Your image here -->
      <img src="static/images/截屏2023-12-08 14.18.55.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Experimental results on the test set.
      </h2> 
    </div>

    <div class="item">
      <!-- Your image here -->
      <img src="static/images/截屏2023-12-11 11.08.12.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Comparing the expression editing of FastComposer, which is based on the CLIP Image Encoder for extracting ID features, with PortraitBooth.
      </h2> 
    </div>





  </div>
</div>
</div>
</section>
<!-- End image carousel -->






<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
